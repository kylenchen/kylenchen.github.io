<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>聚类分析——K-means算法 | Kylen's Blog</title><meta name="description" content="聚类分析——K-means算法"><meta name="keywords" content="python,机器学习"><meta name="author" content="Kylen Chan"><meta name="copyright" content="Kylen Chan"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC&amp;family=Ma+Shan+Zheng&amp;display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="https://chenbw.top/posts/kmeans/"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="聚类分析——K-means算法"><meta name="twitter:description" content="聚类分析——K-means算法"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/cover/kmeans.png"><meta property="og:type" content="article"><meta property="og:title" content="聚类分析——K-means算法"><meta property="og:url" content="https://chenbw.top/posts/kmeans/"><meta property="og:site_name" content="Kylen's Blog"><meta property="og:description" content="聚类分析——K-means算法"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/cover/kmeans.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="prev" title="MySQL数据库下载与安装配置(Windows)" href="https://chenbw.top/posts/install-mysql/"><link rel="next" title="Python生产消费Kafka实例" href="https://chenbw.top/posts/python-kafka/"><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lazyload avatar_img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">19</div></a></div></div><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">7</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/webnav/"><i class="fa-fw fa fa-paper-plane"></i><span> 导航</span></a></li><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fa fa-book"></i><span> 书单</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#分类与聚类"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">分类与聚类</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#k均值-k-means-算法"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">k均值(k-means)算法</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#计算简介"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">计算简介</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#算法描述"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">算法描述</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#优缺点"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">优缺点</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#二维数据聚类实例"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">二维数据聚类实例</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#K-means算法"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">K-means算法</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#Scikit-learn中K-means算法"><span class="toc_mobile_items-number">3.2.</span> <span class="toc_mobile_items-text">Scikit-learn中K-means算法</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#应用场景"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">应用场景</span></a></li></ol></div></div></div><script>var GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://jerryc.me/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  highlight_copy: 'true',
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  highlight_shrink: 'false',
  bookmark: {
    title: '添加书签',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  islazyload: true,
  runtime_unit: '天'


}</script><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#分类与聚类"><span class="toc-number">1.</span> <span class="toc-text">分类与聚类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#k均值-k-means-算法"><span class="toc-number">2.</span> <span class="toc-text">k均值(k-means)算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#计算简介"><span class="toc-number">2.1.</span> <span class="toc-text">计算简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#算法描述"><span class="toc-number">2.2.</span> <span class="toc-text">算法描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#优缺点"><span class="toc-number">2.3.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#二维数据聚类实例"><span class="toc-number">3.</span> <span class="toc-text">二维数据聚类实例</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-means算法"><span class="toc-number">3.1.</span> <span class="toc-text">K-means算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scikit-learn中K-means算法"><span class="toc-number">3.2.</span> <span class="toc-text">Scikit-learn中K-means算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#应用场景"><span class="toc-number">4.</span> <span class="toc-text">应用场景</span></a></li></ol></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/header/post-bg.jpg)"><header><div id="page-header"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Kylen's Blog</a></span><i class="fa fa-bars toggle-menu pull-right close" aria-hidden="true"><!--.open.toggle-menu.pull-right//.menu-icon-first
//.menu-icon-second
//.menu-icon-third
--></i><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 娱乐</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/webnav/"><i class="fa-fw fa fa-paper-plane"></i><span> 导航</span></a></li><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/books/"><i class="fa-fw fa fa-book"></i><span> 书单</span></a></li><li><a class="site-page" href="/gallery/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li></ul></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="post-info"><div id="post-title"><div class="posttitle">聚类分析——K-means算法</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-01-31<span class="post-meta__separator">|</span><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-05-29</time><span class="post-meta__separator mobile_hidden">|</span><span class="mobile_hidden"><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></span><div class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计: </span><span class="word-count">2.7k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 9 分钟</span><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"></i><span>阅读量: </span><span id="busuanzi_value_page_pv"></span></div></div></div></div><div class="layout layout_post" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h2 id="分类与聚类"><a href="#分类与聚类" class="headerlink" title="分类与聚类"></a>分类与聚类</h2><p><strong>分类：</strong> 类别是已知的，通过对已知分类的数据进行训练和学习，找到这些不同类的特征，再对未分类的数据进行分类。属于监督学习。</p>
<p><strong>聚类：</strong> 事先不知道数据会分为几类，通过聚类分析将数据聚合成几个群体。聚类不需要对数据进行训练和学习。属于无监督学习。<a id="more"></a></p>
<h2 id="k均值-k-means-算法"><a href="#k均值-k-means-算法" class="headerlink" title="k均值(k-means)算法"></a>k均值(k-means)算法</h2><p>所谓聚类问题，就是给定一个元素集合D，其中每个元素具有n个可观察属性，使用某种算法将D划分成k个子集，要求每个子集内部的元素之间相异度尽可能低，而不同子集的元素相异度尽可能高。其中每个子集叫做一个簇。 与分类不同，分类是示例式学习，要求分类前明确各个类别，并断言每个元素映射到一个类别，而聚类是观察式学习，在聚类前可以不知道类别甚至不给定类别数量，是无监督学习的一种。目前聚类广泛应用于统计学、生物学、数据库技术和市场营销等领域，相应的算法也非常的多。本文仅介绍一种最简单的聚类算法——k均值（k-means）算法。</p>
<h3 id="计算简介"><a href="#计算简介" class="headerlink" title="计算简介"></a>计算简介</h3><p>k-means算法，也被称为k-平均或k-均值，是一种得到最广泛使用的聚类算法。 它是将各个聚类子集内的所有数据样本的均值作为该聚类的代表点。<br><strong>算法的主要思想</strong>是通过迭代过程把数据集划分为不同的类别，使得评价聚类性能的准则函数达到最优，从而使生成的每个聚类内紧凑，类间独立。这一算法不适合处理离散型属性，但是对于连续型具有较好的聚类效果。</p>
<h3 id="算法描述"><a href="#算法描述" class="headerlink" title="算法描述"></a>算法描述</h3><p>输入：簇的数目k和包含n个对象的数据库。<br>输出：k个簇，使平方误差准则最小。</p>
<p><strong>算法步骤：</strong></p>
<ol>
<li>为每个聚类确定一个初始聚类中心，这样就有K个初始聚类中心。</li>
<li>将样本集中的样本按照最小距离原则分配到最邻近聚类</li>
<li>使用每个聚类中的样本均值作为新的聚类中心。</li>
<li>重复步骤2.3直到聚类中心不再变化。</li>
</ol>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点：</strong></p>
<ul>
<li>原理简单，速度快</li>
<li>扩展性良好(大部分的计算都可以并行计算)</li>
<li>对大数据集有比较好的伸缩性</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>需要指定聚类数量K(要生成的簇的数目)</li>
<li>对异常值敏感，因为算法并没有办法剔除异常值</li>
<li>对初始值敏感，对于不同的初始值，可能会导致不同结果</li>
<li>在簇的平均值被定义的情况下才能使用，这对于处理符号属性的数据不适用</li>
</ul>
<h2 id="二维数据聚类实例"><a href="#二维数据聚类实例" class="headerlink" title="二维数据聚类实例"></a>二维数据聚类实例</h2><h3 id="K-means算法"><a href="#K-means算法" class="headerlink" title="K-means算法"></a>K-means算法</h3><p>二维样本数据集，python3实现过程如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#load data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines(): <span class="comment">#for each line</span></span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float,curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"><span class="comment"># 簇</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#distance func</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span><span class="params">(vecA,vecB)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.sum(np.power(vecA - vecB, <span class="number">2</span>)))  <span class="comment"># la.norm(vecA-vecB) 向量AB的欧式距离</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#init K points randomly</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span><span class="params">(dataSet, k)</span>:</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]</span><br><span class="line">    centroids = np.mat(np.zeros((k,n)))<span class="comment">#create centroid mat</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):<span class="comment">#create random cluster centers, within bounds of each dimension</span></span><br><span class="line">        minJ = np.min(dataSet[:,j])</span><br><span class="line">        rangeJ = float(np.max(dataSet[:,j]) - minJ)</span><br><span class="line">        centroids[:,j] = np.mat(minJ + rangeJ * np.random.rand(k,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"><span class="comment">#K-均值算法:</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span><span class="params">(dataSet,k,distMeas=distEclud,createCent=randCent)</span>:</span></span><br><span class="line">    <span class="comment">#参数：dataset,num of cluster,distance func,initCen</span></span><br><span class="line">    m=np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    clusterAssment=np.mat(np.zeros((m,<span class="number">2</span>)))<span class="comment">#store the result matrix,2 cols for index and error</span></span><br><span class="line">    centroids=createCent(dataSet,k)</span><br><span class="line">    clusterChanged=<span class="literal">True</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged=<span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):<span class="comment">#for every points</span></span><br><span class="line">            minDist = float(<span class="string">'inf'</span>);</span><br><span class="line">            minIndex = <span class="number">-1</span> <span class="comment">#init</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):<span class="comment">#for every k centers，find the nearest center</span></span><br><span class="line">                distJI=distMeas(centroids[j,:],dataSet[i,:])</span><br><span class="line">                <span class="keyword">if</span> distJI&lt;minDist:<span class="comment">#if distance is shorter than minDist</span></span><br><span class="line">                    minDist=distJI;</span><br><span class="line">                    minIndex=j<span class="comment"># update distance and index(类别)</span></span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i,<span class="number">0</span>] != minIndex:</span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">                <span class="comment">#此处判断数据点所属类别与之前是否相同（是否变化，只要有一个点变化就重设为True，再次迭代）</span></span><br><span class="line">            clusterAssment[i,:] = minIndex,minDist**<span class="number">2</span></span><br><span class="line">        <span class="comment">#print(centroids)</span></span><br><span class="line">        <span class="comment"># update k center</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> range(k):</span><br><span class="line">            ptsInClust=dataSet[np.nonzero(clusterAssment[:,<span class="number">0</span>].A==cent)[<span class="number">0</span>]]</span><br><span class="line">            centroids[cent,:] = np.mean(ptsInClust,axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> centroids,clusterAssment</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span><span class="params">(filename)</span>:</span></span><br><span class="line">        <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">        <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    myCentroids, clustAssing = kMeans(datMat, k)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    scatterMarkers=[<span class="string">'s'</span>, <span class="string">'o'</span>, <span class="string">'^'</span>, <span class="string">'p'</span>, <span class="string">'8'</span>, <span class="string">'d'</span>, <span class="string">'v'</span>, <span class="string">'h'</span>, <span class="string">'&gt;'</span>, <span class="string">'&lt;'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        x1 = [];  y1 = []</span><br><span class="line">        markerStyle = scatterMarkers[i % len(scatterMarkers)]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(datMat)):</span><br><span class="line">            <span class="keyword">if</span> clustAssing[j][:,<span class="number">0</span>] == i:</span><br><span class="line">               x1.append(datMat[j][:,<span class="number">0</span>])</span><br><span class="line">               y1.append(datMat[j][:,<span class="number">1</span>])</span><br><span class="line">        ax.scatter(x1, y1, alpha=<span class="number">1</span>,marker=markerStyle ,s=<span class="number">50</span>)</span><br><span class="line">        ax.scatter([myCentroids[:, <span class="number">0</span>]], [myCentroids[:, <span class="number">1</span>]], s=<span class="number">120</span>, marker=<span class="string">'+'</span>,c=<span class="string">'b'</span>)</span><br><span class="line">    plt.title(<span class="string">'K-means'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Y'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ ==<span class="string">"__main__"</span>:</span><br><span class="line">    plotDataSet(<span class="string">'testSet.txt'</span>)</span><br></pre></td></tr></table></figure><br>聚类结果显示。将聚类划分为不同簇的数据，用不同的颜色和符号进行显示，同时画出最终的聚类中心。<br><img src= "/img/loading.gif" data-src="https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/post/kmeans/1.png" alt="K-means算法"></p>
<h3 id="Scikit-learn中K-means算法"><a href="#Scikit-learn中K-means算法" class="headerlink" title="Scikit-learn中K-means算法"></a>Scikit-learn中K-means算法</h3><p>Scikit-learn中有很多种K-means算法，这里使用传统的K-means，同样以二维样本数据集为例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span><span class="params">(fileName)</span>:</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = open(fileName)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines(): <span class="comment">#for each line</span></span><br><span class="line">        curLine = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        fltLine = list(map(float,curLine))</span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line">data = np.array(loadDataSet(<span class="string">'testSet.txt'</span>))</span><br><span class="line"></span><br><span class="line">k = <span class="number">4</span>  <span class="comment"># 簇</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line"></span><br><span class="line">estimator = KMeans(n_clusters=<span class="number">4</span>, random_state=<span class="number">9</span>)</span><br><span class="line"><span class="comment"># fit_predict表示拟合+预测，也可以分开写</span></span><br><span class="line">res = estimator.fit_predict(data)</span><br><span class="line"><span class="comment"># 各个类别的聚类中心值</span></span><br><span class="line">centroids = estimator.cluster_centers_</span><br><span class="line"><span class="comment"># 预测类别标签结果</span></span><br><span class="line">lable_pred = estimator.labels_</span><br><span class="line"><span class="comment"># 聚类中心均值向量的总和</span></span><br><span class="line">inertia = estimator.inertia_</span><br><span class="line"></span><br><span class="line">scatterMarkers=[<span class="string">'s'</span>, <span class="string">'o'</span>, <span class="string">'^'</span>, <span class="string">'p'</span>, <span class="string">'8'</span>, <span class="string">'d'</span>, <span class="string">'v'</span>, <span class="string">'h'</span>, <span class="string">'&gt;'</span>, <span class="string">'&lt;'</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">    markerStyle = scatterMarkers[i % len(scatterMarkers)]</span><br><span class="line">    x1 = []; y1=[]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        <span class="keyword">if</span> lable_pred[j] == i:</span><br><span class="line">            x1.append(data[j, <span class="number">0</span>])</span><br><span class="line">            y1.append(data[j, <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># ax.scatter(data[:, 0], data[:, 1], c=res, marker=markerStyle)</span></span><br><span class="line">    ax.scatter(x1, y1,alpha=<span class="number">1</span>, marker=markerStyle ,s=<span class="number">50</span>)</span><br><span class="line">    ax.scatter(centroids[:,<span class="number">0</span>], centroids[:,<span class="number">1</span>],marker=<span class="string">'+'</span>,s=<span class="number">120</span>,c=<span class="string">'b'</span>)</span><br><span class="line">plt.title(<span class="string">'sklearnKMeans'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'X'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Y'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>聚类效果用散点图如下图所示。<br><img src= "/img/loading.gif" data-src="https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/post/kmeans/2.png" alt="Scikit-learn中K-means算法"></p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p><strong>1.文档分类器</strong></p>
<p>根据标签、主题和文档内容将文档分为多个不同的类别。这是一个非常标准且经典的K-means算法分类问题。首先，需要对文档进行初始化处理，将每个文档都用矢量来表示，并使用术语频率来识别常用术语进行文档分类，这一步很有必要。然后对文档向量进行聚类，识别文档组中的相似性。 这里是用于文档分类的K-means算法实现案例。</p>
<p><strong>2.物品传输优化</strong></p>
<p>使用K-means算法的组合找到无人机最佳发射位置和遗传算法来解决旅行商的行车路线问题，优化无人机物品传输过程。这是该项目的白皮书。</p>
<p><strong>3.识别犯罪地点</strong></p>
<p>使用城市中特定地区的相关犯罪数据，分析犯罪类别、犯罪地点以及两者之间的关联，可以对城市或区域中容易犯罪的地区做高质量的勘察。这是基于德里飞行情报区犯罪数据的论文。</p>
<p><strong>4.客户分类</strong></p>
<p>聚类能过帮助营销人员改善他们的客户群（在其目标区域内工作），并根据客户的购买历史、兴趣或活动监控来对客户类别做进一步细分。这是关于电信运营商如何将预付费客户分为充值模式、发送短信和浏览网站几个类别的白皮书。对客户进行分类有助于公司针对特定客户群制定特定的广告。</p>
<p><strong>5.球队状态分析</strong></p>
<p>分析球员的状态一直都是体育界的一个关键要素。随着竞争越来愈激烈，机器学习在这个领域也扮演着至关重要的角色。如果你想创建一个优秀的队伍并且喜欢根据球员状态来识别类似的球员，那么K-means算法是一个很好的选择。具体细节和实现请参照这篇文章。</p>
<p><strong>6.保险欺诈检测</strong></p>
<p>机器学习在欺诈检测中也扮演着一个至关重要的角色，在汽车、医疗保险和保险欺诈检测领域中广泛应用。利用以往欺诈性索赔的历史数据，根据它和欺诈性模式聚类的相似性来识别新的索赔。由于保险欺诈可能会对公司造成数百万美元的损失，因此欺诈检测对公司来说至关重要。这是汽车保险中使用聚类来检测欺诈的白皮书。</p>
<p><strong>7.乘车数据分析</strong></p>
<p>面向大众公开的Uber乘车信息的数据集，为我们提供了大量关于交通、运输时间、高峰乘车地点等有价值的数据集。分析这些数据不仅对Uber大有好处，而且有助于我们对城市的交通模式进行深入的了解，来帮助我们做城市未来规划。这是一篇使用单个样本数据集来分析Uber数据过程的文章。</p>
<p><strong>8.网络分析犯罪分子</strong></p>
<p>网络分析是从个人和团体中收集数据来识别二者之间的重要关系的过程。网络分析源自于犯罪档案，该档案提供了调查部门的信息，以对犯罪现场的罪犯进行分类。这是一篇在学术环境中，如何根据用户数据偏好对网络用户进行 cyber-profile的论文。</p>
<p><strong>9.呼叫记录详细分析</strong></p>
<p>通话详细记录（CDR）是电信公司在对用户的通话、短信和网络活动信息的收集。将通话详细记录与客户个人资料结合在一起，这能够帮助电信公司对客户需求做更多的预测。在这篇文章中，你将了解如何使用无监督K-Means聚类算法对客户一天24小时的活动进行聚类，来了解客户数小时内的使用情况。</p>
<p><strong>10.IT警报的自动化聚类</strong></p>
<p>大型企业IT基础架构技术组件（如网络，存储或数据库）会生成大量的警报消息。由于警报消息可以指向具体的操作，因此必须对警报信息进行手动筛选，确保后续过程的优先级。对数据进行聚类可以对警报类别和平均修复时间做深入了解，有助于对未来故障进行预测。</p>
<p><strong>参考：</strong></p>
<ol>
<li><a href="https://yq.aliyun.com/articles/573745?spm=a2c41.11181499.0.0" target="_blank" rel="noopener">K-Means算法的10个有趣用例</a></li>
</ol>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Kylen Chan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://chenbw.top/posts/kmeans/">https://chenbw.top/posts/kmeans/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://chenbw.top">Kylen's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python/">python</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/cover/kmeans.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull-left"><a href="/posts/install-mysql/"><img class="prev_cover" data-src="https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/cover/install-mysql.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>MySQL数据库下载与安装配置(Windows)</span></div></a></div><div class="next-post pull-right"><a href="/posts/python-kafka/"><img class="next_cover" data-src="https://cdn.jsdelivr.net/gh/kylenchen/CDN@latest/cover/python-kafka.png" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>Python生产消费Kafka实例</span></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div class="vcomment"></div><!-- script(src='https://cdn1.lncld.net/static/js/3.0.4/av-min.js')--><!-- script(src=url_for('/js/av-min.js'))--><!-- script(src=url_for('/js/Valine.min.js'))--><script src="/js/MiniValine.min.js"></script><!-- script(src='https://unpkg.com/minivaline@2.7.3/dist/MiniValine.min.js')--><script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new MiniValine({
  el:'.vcomment',
  notify:notify,
  verify:verify,
  emoticon_url:  '/img/alu',
  emoticon_list: ["吐.png","喷血.png","狂汗.png","不说话.png","汗.png","坐等.png","献花.png","不高兴.png","中刀.png","害羞.png","皱眉.png","小眼睛.png","中指.png","尴尬.png","瞅你.png","想一想.png","中枪.png","得意.png","肿包.png","扇耳光.png","亲亲.png","惊喜.png","脸红.png","无所谓.png","便便.png","愤怒.png","蜡烛.png","献黄瓜.png","内伤.png","投降.png","观察.png","看不见.png","击掌.png","抠鼻.png","邪恶.png","看热闹.png","口水.png","抽烟.png","锁眉.png","装大款.png","吐舌.png","无奈.png","长草.png","赞一个.png","呲牙.png","无语.png","阴暗.png","不出所料.png","咽气.png","期待.png","高兴.png","吐血倒地.png","哭泣.png","欢呼.png","黑线.png","喜极而泣.png","喷水.png","深思.png","鼓掌.png","暗地观察.png"],
  appId:'pyWQeT2J9Kmq3AtbGoUphuEL-gzGzoHsz',
  appKey:'geHKUsFzyUOG3Ti4pwgvHDfD',
  placeholder:'Write a comment',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10',
  lang: 'zh-CN'
})</script></div></div></div><footer><div class="layout" id="footer"><div class="copyright">Copyright &copy;2018 - 2020 By Kylen Chan</div><div class="footer_custom_text">未来未至,  至所未致</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><section class="rightside" id="rightside"><i class="fa fa-list-ul close" id="mobile-toc-button" title="rightside.toc" aria-hidden="true"></i><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换">繁</a><i class="fa fa-moon-o nightshift" id="nightshift" title="夜间模式"></i></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2.2.1/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script async src="/js/search/local-search.js"></script><script src="https://cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script src="/js/nightshift.js"></script><script id="ribbon" src="https://cdn.jsdelivr.net/gh/jerryc127/CDN@latest/js/piao.js"></script><script src="/js/tw_cn.js"></script><script>translateInitilization()

</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.iife.min.js" async></script><!--script.// const observer = lozad(); // lazy loads elements with default selector as '.lozad'
// observer.observe();--><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>